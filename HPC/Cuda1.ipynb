{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrg4vQmL0c9y",
        "outputId": "2443e08d-123e-49f9-c250-d61cd9dc7bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdVqaZu1QFe",
        "outputId": "cd984227-10c9-4f8f-fa75-c89a31b05e8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpnbu22tu2\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel to add two vectors\n",
        "__global__\n",
        "void vectorAdd(int *a, int *b, int *c, int size) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < size) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = 1000000; // Size of the vectors\n",
        "    int *a, *b, *c; // Host vectors\n",
        "    int *d_a, *d_b, *d_c; // Device vectors\n",
        "\n",
        "    // Allocate memory for host vectors\n",
        "    a = (int*)malloc(size * sizeof(int));\n",
        "    b = (int*)malloc(size * sizeof(int));\n",
        "    c = (int*)malloc(size * sizeof(int));\n",
        "\n",
        "    // Initialize host vectors\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        a[i] = i;\n",
        "        b[i] = size - i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for device vectors\n",
        "    cudaMalloc(&d_a, size * sizeof(int));\n",
        "    cudaMalloc(&d_b, size * sizeof(int));\n",
        "    cudaMalloc(&d_c, size * sizeof(int));\n",
        "\n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy(d_a, a, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, size);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(c, d_c, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verify result\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4ZLZPAp18Ev",
        "outputId": "996bf643-9910-4ff5-f133-4a676632532c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 + 1000000 = 1000000\n",
            "1 + 999999 = 1000000\n",
            "2 + 999998 = 1000000\n",
            "3 + 999997 = 1000000\n",
            "4 + 999996 = 1000000\n",
            "5 + 999995 = 1000000\n",
            "6 + 999994 = 1000000\n",
            "7 + 999993 = 1000000\n",
            "8 + 999992 = 1000000\n",
            "9 + 999991 = 1000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 512\n",
        "\n",
        "// CUDA kernel to perform matrix multiplication\n",
        "__global__\n",
        "void matrixMul(int *a, int *b, int *c, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < width; ++i) {\n",
        "            sum += a[row * width + i] * b[i * width + col];\n",
        "        }\n",
        "        c[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *a, *b, *c; // Host matrices\n",
        "    int *d_a, *d_b, *d_c; // Device matrices\n",
        "\n",
        "    // Allocate memory for host matrices\n",
        "    a = (int*)malloc(N * N * sizeof(int));\n",
        "    b = (int*)malloc(N * N * sizeof(int));\n",
        "    c = (int*)malloc(N * N * sizeof(int));\n",
        "\n",
        "    // Initialize host matrices\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        a[i] = i;\n",
        "        b[i] = i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for device matrices\n",
        "    cudaMalloc(&d_a, N * N * sizeof(int));\n",
        "    cudaMalloc(&d_b, N * N * sizeof(int));\n",
        "    cudaMalloc(&d_c, N * N * sizeof(int));\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockDim(32, 32);\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMul<<<gridDim, blockDim>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verify result (printing a few elements)\n",
        "    printf(\"Result (a few elements):\\n\");\n",
        "    for (int i = 0; i < 5; ++i) {\n",
        "        for (int j = 0; j < 5; ++j) {\n",
        "            printf(\"%d \", c[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msv8ctk0k7wo",
        "outputId": "6d02bd4c-05ec-4ddf-bd18-440bb99ead18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result (a few elements):\n",
            "1364590592 1364721408 1364852224 1364983040 1365113856 \n",
            "1297481728 1297874688 1298267648 1298660608 1299053568 \n",
            "1230372864 1231027968 1231683072 1232338176 1232993280 \n",
            "1163264000 1164181248 1165098496 1166015744 1166932992 \n",
            "1096155136 1097334528 1098513920 1099693312 1100872704 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tg-Jn5cTk9Gc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}